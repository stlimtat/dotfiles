#!/usr/bin/env zsh
# .abnormal
# For lvim - abnormal
# https://www.lunarvim.org/
export SOURCE=${HOME}/dev/source

#   alias vim="PYTHONPATH=${SOURCE}/src/py:${SOURCE}/src/pytests:${SOURCE}/src/pytests/abnormal/test ${HOME}/.local/bin/lvim"
# fi
# For astrovim or lazyvim
if [[ -f "${HOME}/.config/nvim/config.ld" || -f "${HOME}/.config/nvim/lazy-lock.json" ]]; then
  alias vim="PYTHONPATH=${SOURCE}/src/py:${SOURCE}/src/pytests:${SOURCE}/src/pytests/abnormal/test $(brew --prefix )/bin/nvim"
fi

# Some abnormal security stuff
alias airflow_worker_ips="aws ec2 describe-instances --filters Name=tag:Name,Values=airflow-worker-prod | jq -r '.Reservations[].Instances[].PrivateIpAddress' | sort "
alias airflow_onboarding_worker_ips="aws ec2 describe-instances --filters Name=tag:Name,Values=airflow-worker-onboarding | jq -r '.Reservations[].Instances[].PrivateIpAddress' | sort"
# helm publish airflow
alias gh_publish_airflow_prod="gh workflow run publish_bento_image_ecr.yml --ref $(git rev-parse --abbrev-ref HEAD) -f bento_target='gtm/onboarding/airflow' -f environments='prod' -f region_eu=false -f region_us=true -f region_us_legacy=false -f instance_tags='cd cd-arm' && gh run list --workflow=publish_bento_image_ecr.yml"
alias gh_publish_airflow_test="gh workflow run publish_bento_image_ecr.yml --ref $(git rev-parse --abbrev-ref HEAD) -f bento_target='gtm/onboarding/airflow' -f environments='test' -f region_eu=false -f region_us=true -f region_us_legacy=false -f instance_tags='cd cd-arm' && gh run list --workflow=publish_bento_image_ecr.yml"
# change absec
alias absec_legacy="export ABSEC_CLOUD=aws; export ABSEC_ENV=prod; export ABSEC_PART=management; export ABSEC_REGION=us-east-1"
alias absec_test="export ABSEC_CLOUD=aws; export ABSEC_ENV=test; export ABSEC_PART=test; export ABSEC_REGION=us-east-2"

# Abnormal
export ABNORMAL_USER=slim
export ABSEC_CLOUD=aws
export ABSEC_ENV=prod
export ABSEC_IDENTITY="aid://user/slim"
export ABSEC_PART=management
export ABSEC_REGION=us-east-1
export INFRA=${HOME}/dev/infrastructure
export GOFLAGS="-tags=dynamic"
# Stop Terraform from barfing on ARM Macbooks
export GODEBUG=asyncpreemptoff=1
export MTLS_HOME=${HOME}/.mtls/user
export PKG_CONFIG_PATH=$(brew --prefix openssl@1.1)/lib/pkgconfig
export STORAGE_ACCOUNT_URL="https://abnormaldataneu.blob.core.windows.net"
export TERRAGRUNT_SOURCE_MAP="git::ssh://git@github.com/abnormal-security/infrastructure-modules.git=${HOME}/dev/infrastructure-modules"
export TERRAGRUNT_SOURCE_UPDATE=true
export VENV=${HOME}/dev/venv
start_time=$(gdate +%s%3N)
echo "Running abnormal/tools/bash/prelude...${start_time}ms"
source ${SOURCE}/tools/bash/prelude.sh
end_time=$(gdate +%s%3N)
time_taken=$((end_time - start_time))
echo "Running abnormal/tools/bash/prelude...${end_time}ms...${time_taken}ms...Done"
start_time=$(gdate +%s%3N)
echo "Running venv-activate...${start_time}ms...deactivate" && \
  deactivate() 2>&1
echo "Running venv-activate...${start_time}ms...activate" && \
  source ${SOURCE}/tools/dev/venv-activate 2>&1
end_time=$(gdate +%s%3N)
time_taken=$((end_time - start_time))
echo "Running venv-activate...${end_time}ms...${time_taken}ms...Done"
# AWS_PROFILE must be set after bash_includes
export AWS_PROFILE=absec-mgmt

# Unwanted Mail env
export UNWANTEDMAIL_SERVICE_ENV=staging
export HOSTING_DOMAIN=aws
export KAFKA_CACERT_PATH=$VENV/lib/python3.8/site-packages/certifi/cacert.pem

LD_LIBRARY_PATH=/usr/local/opt/openssl/lib:${LD_LIBRARY_PATH}
CPATH=/usr/local/opt/openssl/include:${CPATH}
PKG_CONFIG_PATH=/usr/local/opt/openssl/lib/pkgconfig:${PKG_CONFIG_PATH}
export LD_LIBRARY_PATH CPATH PKG_CONFIG_PATH

start_time=$(gdate +%s%3N)
echo "Running colima...${start_time}ms"
eval "$(colima completion zsh)"
end_time=$(gdate +%s%3N)
time_taken=$((end_time - start_time))
echo "Running colima...${end_time}ms...${time_taken}ms...Done"

alias unset_absec="unset ABSEC_CLOUD ABSEC_ENV ABSEC_IDENTITY ABSEC_PART ABSEC_REGION"

# Adding a function in bash_profile
function broadcast_to_airflow_onboarding_workers() {
  BROADCAST_COMMAND="\"$1\""
  echo "Broadcasting command: $BROADCAST_COMMAND"

  output_file="/tmp/broadcast_output.txt"
  echo "" >> $output_file
  # tail -f $output_file &
  # for IP_ADDRESS in "space-separated recipient IP addresses"
  for IP_ADDRESS in $(airflow_onboarding_worker_ips)
  do
    echo $IP_ADDRESS >> $output_file
    echo "ssh -t $IP_ADDRESS \"docker exec -it \\\$(docker container ps -f name=airflow-worker | sed -n '2 p' | cut -f1 -d' ' ) /bin/bash -c -i $BROADCAST_COMMAND\""
    # infocmp -a xterm-kitty | ssh $IP_ADDRESS tic -x -o \~/.terminfo /dev/stdin
    ssh -t $IP_ADDRESS "docker exec -it \$(docker container ps -f name=airflow-worker | sed -n '2 p' | cut -f1 -d' ' ) /bin/bash -c -i $BROADCAST_COMMAND" >> $output_file
    echo "##################################################" >> $output_file
  done
  fg
}

# https://docs.aws.amazon.com/AmazonS3/latest/userguide/example_s3_DeleteObjects_section.html
###############################################################################
# function errecho
#
# This function outputs everything sent to it to STDERR (standard error output).
###############################################################################
function errecho() {
  printf "%s\n" "$*" 1>&2
}

###############################################################################
# function delete_items_in_bucket
#
# This function deletes the specified list of keys from the specified bucket.
#
# Parameters:
#       $1 - The name of the bucket.
#       $2 - A list of keys in the bucket to delete.

# Returns:
#       0 - If successful.
#       1 - If it fails.
###############################################################################
function delete_s3_buckets() {
  local bucket_name=$1
  local keys=$2
  local response

  # Create the JSON for the items to delete.
  local delete_items
  delete_items="{\"Objects\":["
  for key in $keys; do
    delete_items="$delete_items{\"Key\": \"$key\"},"
  done
  delete_items=${delete_items%?} # Remove the final comma.
  delete_items="$delete_items]}"

  response=$(aws s3api delete-objects \
    --bucket "$bucket_name" \
    --delete "$delete_items")

  # shellcheck disable=SC2181
  if [[ $? -ne 0 ]]; then
    errecho "ERROR:  AWS reports s3api delete-object operation failed.\n$response"
    return 1
  fi
}


function run_prod_proxy() {
  [[ $AWS_PROFILE =~ .*-dbadmin ]] || export AWS_PROFILE=$(aws configure list-profiles | grep dbadmin | fzf --header="Pick an AWS profile. (Careful -- This determines the kind of access you'll have)")
  # Assumes that you are logged in as db admin on sso if there is something in ~/.aws/cli/cache/
  [[ -z "$( gfind $HOME/.aws/cli/cache -mmin -120 )" ]] && aws sso login --profile $AWS_PROFILE
  export CONTEXT=$(kubectl config view -o jsonpath='{range .contexts[*]}{.name}{"\n"}{end}' | fzf --header="Choose the correct kubecontext for the environment you are trying to access.")
  export NAMESPACE=$(kubectl --context $CONTEXT get ns -o json | jq -r '.items | map(.metadata.name) | .[]' | fzf --header="Pick the namespace that corresponds to your database.")
  export REGION=$(echo "us-east-1\nus-east-2\neu-west-1" | fzf --header="Pick a region. This affects which region AWS commands are run in.")
  export PGPORT=54320
  echo "Using port 54320 by default for the database."
  export TARGET=$(aws rds --region $REGION describe-db-instances | jq -r '.DBInstances | .[] | .Endpoint.Address' | fzf --header="Pick the RDS Host you want to connect to"):$PGPORT
  export LOCAL_PORT=54320
  echo "Using port 54320 by default for the proxy."
  export RUN_MODE=inline
  export USER=slim
  prod-proxy start
}

function connect_pgdb() {
  export PGUSER=$(echo "platformadmin\nadmin\nrw\nro" | fzf  --header="Pick a user.")
  export ABNORMAL_USER=$(aws sts get-caller-identity --query UserId --output text | cut -f2 -d ':' | cut -f1 -d '@')
  export ABSEC_IDENTITY=aid://user/$ABNORMAL_USER/$PGUSER
  [[ $AWS_PROFILE =~ .*-dbadmin ]] || export AWS_PROFILE=$(aws configure list-profiles | grep dbadmin | fzf --header="Pick an AWS profile. (Careful -- This determines the kind of access you'll have)")
  # Assumes that you are logged in as db admin on sso if there is something in ~/.aws/cli/cache/
  [[ -z "$( gfind $HOME/.aws/cli/cache -mmin -120 )" ]] && aws sso login --profile $AWS_PROFILE
  export CONTEXT=$(kubectl config view -o jsonpath='{range .contexts[*]}{.name}{"\n"}{end}' | fzf --header="Choose the correct kubecontext for the environment you are trying to access.")
  export MY_ENV=$(echo $CONTEXT | cut -f2 -d-)
  export NAMESPACE=$(kubectl --context $CONTEXT get ns -o json | jq -r '.items | map(.metadata.name) | .[]' | fzf --header="Pick the namespace that corresponds to your database.")
  export MY_PRODUCT=$(echo $MY_APP | cut -f1 -d--)
  export MY_APP=$(echo $MY_APP | cut -f2 -d--)
  export REGION=$(echo "us-east-1\nus-east-2\neu-west-1" | fzf --header="Pick a region. This affects which region AWS commands are run in.")
  export RDSHOST=$(aws rds --region $REGION describe-db-instances | jq -r '.DBInstances | .[] | .Endpoint.Address' | fzf --header="Pick the RDS Host you want to connect to")
  export PGHOST=$(echo "$RDSHOST\n127.0.0.1" | fzf --header "Pick the host to connect to using psql. If you are using a proxy, use localhost.")
  export PGPORT=54320
  echo "Using port 54320 by default."
  export PGSSLMODE=verify-ca
  export PGSSLROOTCERT=$(mktemp -d | xargs -I% bash -c "curl https://s3.amazonaws.com/rds-downloads/rds-ca-2019-root.pem > %/cert.pem; echo %/cert.pem;")
  export PGDATABASE=$(aws rds --region $REGION describe-db-instances | jq -r '.DBInstances | map(.TagList) | map(map(select(.Key == "pac-application"))) | map(map(.Value)) | map(.[0]) | map(select(.)) | map(gsub("-";"")) | unique | .[]' | fzf --header "Pick the database name. (This information was picked out from the application name. Please contact #pi-data-platform if this doesnt correspond.")
  # export PGDATABASE=employeeservice
  export PGPASSWORD="$(aws rds generate-db-auth-token --hostname $RDSHOST --port $PGPORT --region $REGION --username $PGUSER)"
  export ABDJANGO_USER=$( [[ "$PGUSER" == "rw" ]] && echo "writer" || echo "reader")
  unset ABSEC_CLOUD ABSEC_ENV ABSEC_PART ABSEC_REGION
  abdjango showconnectioninfo --env $MY_ENV --cloud aws --region $REGION --product $MY_PRODUCT --application $MY_APP --component db --user $ABDJANGO_USER
  read
  psql
}

function connect_kafka() {
  export MSK_ARN=$(aws kafka list-clusters | jq --raw-output ".ClusterInfoList | .[] | .ClusterArn" | fzf)
  export KAFKA_BOOTSTRAP_BROKER=$(aws kafka get-bootstrap-brokers --cluster-arn $MSK_ARN --query BootstrapBrokerStringTls --output text | cut -d, -f1)
  export KAFKA_CLUSTER=(--command-config "${HOME}/.config/kafka/client.properties" --bootstrap-server "${KAFKA_BOOTSTRAP_BROKER}")
}
